{
    "docs": [
        {
            "location": "/", 
            "text": "MCTS\n\n\nThis package implements the Monte-Carlo Tree Search algorithm in Julia for solving Markov decision processes (MDPs). The user should define the problem according to the API in \nPOMDPs.jl\n. Examples of problem definitions can be found in \nPOMDPModels.jl\n. For an extensive tutorial, see \nthis\n notebook.\n\n\nSpecial thanks to Jon Cox for writing the original version of this code.\n\n\n\n\nInstallation\n\n\nAfter installing \nPOMDPs.jl\n, start Julia and run the following command:\n\n\nusing POMDPs\nPOMDPs.add(\nMCTS\n)\n\n\n\n\n\n\nUsage\n\n\nProblems should be defined using the \nPOMDPs.jl generative interface\n. \n\n\nTo see the methods that you need to implement to use MCTS with your MDP (assume you're defining an MDP of type \nMyMDP\n with states represented by integers and 3 possible integer actions), run\n\n\nusing POMDPs\nusing MCTS\n\nimmutable MyMDP \n: MDP{Int,Int} end\nPOMDPs.actions(::MyMDP) = [1,2,3]\n\n@requirements_info MCTSSolver() MyMDP() 1\n\n\n\n\n(the \n1\n is any valid state). This should output something like\n\n\nINFO: POMDPs.jl requirements for action(::AbstractMCTSPlanner, ::Any) and dependencies. ([\u2714] = implemented correctly; [X] = missing)\n\nFor action(::AbstractMCTSPlanner, ::Any):\n  [No additional requirements]\nFor simulate(::AbstractMCTSPlanner, ::Any, ::Int64) (in action(::AbstractMCTSPlanner, ::Any)):\n  [\u2714] discount(::MyMDP)\n  [\u2714] isterminal(::MyMDP, ::Int64)\n  [X] generate_sr(::MyMDP, ::Int64, ::Int64, ::MersenneTwister)\nFor insert_node!(::AbstractMCTSPlanner, ::Any) (in simulate(::AbstractMCTSPlanner, ::Any, ::Int64)):\n  [\u2714] actions(::MyMDP, ::Int64)\n  [\u2714] iterator(::Tuple)\nFor estimate_value(::SolvedRolloutEstimator, ::MDP, ::Any, ::Int64) (in simulate(::AbstractMCTSPlanner, ::Any, ::Int64)):\n  [No additional requirements]\nFor rollout(::SolvedRolloutEstimator, ::MDP, ::Any, ::Int64) (in estimate_value(::SolvedRolloutEstimator, ::MDP, ::Any, ::Int64)):\n  [No additional requirements]\nFor simulate(::RolloutSimulator, ::MDP, ::Policy, ::Any) (in rollout(::SolvedRolloutEstimator, ::MDP, ::Any, ::Int64)):\n  [\u2714] action(::RandomPolicy, ::Int64)\n\n\n\n\nindicating that \ngenerate_sr\n still needs to be implemented for \nMyMDP\n to be used with MCTS. Indeed \ngenerate_sr\n is the most important function needed to use MCTS.\n\n\nNote: MDPs that implement the \nPOMDPs.jl explicit interface\n can also be used with MCTS since the implementation of the explicit interface automatically defines the functions in the generative interface.\n\n\nOnce the above functions are defined, the solver can be called with the following syntax:\n\n\nusing MCTS\n\nmdp = MyMDP() # initializes the MDP\nsolver = MCTSSolver(n_iterations=50, depth=20, exploration_constant=5.0) # initializes the Solver type\nplanner = solve(solver, mdp) # initializes the planner\n\n\n\n\nBy default, the solver will use a random policy for rollouts. If you want to pass in a custom rollout policy you can run:\n\n\nrollout_policy = MyCustomPolicy() # of type Policy, and has method action(rollout_policy::MyCustomPolicy, s::State)\nsolver = MCTSSolver(estimate_value=RolloutEstimator(rollout_policy)) # default solver parameters will be used n_iterations=100, depth=10, exploration_constant=1.0 = solve(solver, mdp)\n\n\n\n\nSince Monte-Carlo Tree Search is an online method, the solve function simply specifies the mdp model to the solver (which is embedded in the policy object). (Note that an MCTSPlanner can also be constructed directly without calling \nsolve()\n.) The computation is done during calls to the action function. To extract the policy for a given state, simply call the action function:\n\n\ns = create_state(mdp) # this can be any valid state\na = action(planner, s) # returns the action for state s\n\n\n\n\n\n\nSolver Variants\n\n\nThere are currently two variants of the MCTS solver along with a Belief MCTS solver that can be used with POMDPs. They are documented in detail in the following sections:\n\n\n\n\nVanilla\n\n\nDouble Progressive Widening\n\n\nBelief MCTS\n\n\n\n\n\n\nVisualization\n\n\nAn example of visualization of the search tree in a jupyter notebook is \nhere\n (or \nhere\n is the version on github that will not display quite right but will still show you how it's done).\n\n\nTo display the tree in a Google Chrome window, run \nusing D3Trees; inchrome(D3Tree(policy, state))\n.\n\n\n\n\nIncorporating Additional Prior Knowledge\n\n\nAn example of incorporating additional prior domain knowledge (to initialize Q and N) and to get an estimate of the value is \nhere\n.", 
            "title": "Home"
        }, 
        {
            "location": "/#mcts", 
            "text": "This package implements the Monte-Carlo Tree Search algorithm in Julia for solving Markov decision processes (MDPs). The user should define the problem according to the API in  POMDPs.jl . Examples of problem definitions can be found in  POMDPModels.jl . For an extensive tutorial, see  this  notebook.  Special thanks to Jon Cox for writing the original version of this code.", 
            "title": "MCTS"
        }, 
        {
            "location": "/#installation", 
            "text": "After installing  POMDPs.jl , start Julia and run the following command:  using POMDPs\nPOMDPs.add( MCTS )", 
            "title": "Installation"
        }, 
        {
            "location": "/#usage", 
            "text": "Problems should be defined using the  POMDPs.jl generative interface .   To see the methods that you need to implement to use MCTS with your MDP (assume you're defining an MDP of type  MyMDP  with states represented by integers and 3 possible integer actions), run  using POMDPs\nusing MCTS\n\nimmutable MyMDP  : MDP{Int,Int} end\nPOMDPs.actions(::MyMDP) = [1,2,3]\n\n@requirements_info MCTSSolver() MyMDP() 1  (the  1  is any valid state). This should output something like  INFO: POMDPs.jl requirements for action(::AbstractMCTSPlanner, ::Any) and dependencies. ([\u2714] = implemented correctly; [X] = missing)\n\nFor action(::AbstractMCTSPlanner, ::Any):\n  [No additional requirements]\nFor simulate(::AbstractMCTSPlanner, ::Any, ::Int64) (in action(::AbstractMCTSPlanner, ::Any)):\n  [\u2714] discount(::MyMDP)\n  [\u2714] isterminal(::MyMDP, ::Int64)\n  [X] generate_sr(::MyMDP, ::Int64, ::Int64, ::MersenneTwister)\nFor insert_node!(::AbstractMCTSPlanner, ::Any) (in simulate(::AbstractMCTSPlanner, ::Any, ::Int64)):\n  [\u2714] actions(::MyMDP, ::Int64)\n  [\u2714] iterator(::Tuple)\nFor estimate_value(::SolvedRolloutEstimator, ::MDP, ::Any, ::Int64) (in simulate(::AbstractMCTSPlanner, ::Any, ::Int64)):\n  [No additional requirements]\nFor rollout(::SolvedRolloutEstimator, ::MDP, ::Any, ::Int64) (in estimate_value(::SolvedRolloutEstimator, ::MDP, ::Any, ::Int64)):\n  [No additional requirements]\nFor simulate(::RolloutSimulator, ::MDP, ::Policy, ::Any) (in rollout(::SolvedRolloutEstimator, ::MDP, ::Any, ::Int64)):\n  [\u2714] action(::RandomPolicy, ::Int64)  indicating that  generate_sr  still needs to be implemented for  MyMDP  to be used with MCTS. Indeed  generate_sr  is the most important function needed to use MCTS.  Note: MDPs that implement the  POMDPs.jl explicit interface  can also be used with MCTS since the implementation of the explicit interface automatically defines the functions in the generative interface.  Once the above functions are defined, the solver can be called with the following syntax:  using MCTS\n\nmdp = MyMDP() # initializes the MDP\nsolver = MCTSSolver(n_iterations=50, depth=20, exploration_constant=5.0) # initializes the Solver type\nplanner = solve(solver, mdp) # initializes the planner  By default, the solver will use a random policy for rollouts. If you want to pass in a custom rollout policy you can run:  rollout_policy = MyCustomPolicy() # of type Policy, and has method action(rollout_policy::MyCustomPolicy, s::State)\nsolver = MCTSSolver(estimate_value=RolloutEstimator(rollout_policy)) # default solver parameters will be used n_iterations=100, depth=10, exploration_constant=1.0 = solve(solver, mdp)  Since Monte-Carlo Tree Search is an online method, the solve function simply specifies the mdp model to the solver (which is embedded in the policy object). (Note that an MCTSPlanner can also be constructed directly without calling  solve() .) The computation is done during calls to the action function. To extract the policy for a given state, simply call the action function:  s = create_state(mdp) # this can be any valid state\na = action(planner, s) # returns the action for state s", 
            "title": "Usage"
        }, 
        {
            "location": "/#solver-variants", 
            "text": "There are currently two variants of the MCTS solver along with a Belief MCTS solver that can be used with POMDPs. They are documented in detail in the following sections:   Vanilla  Double Progressive Widening  Belief MCTS", 
            "title": "Solver Variants"
        }, 
        {
            "location": "/#visualization", 
            "text": "An example of visualization of the search tree in a jupyter notebook is  here  (or  here  is the version on github that will not display quite right but will still show you how it's done).  To display the tree in a Google Chrome window, run  using D3Trees; inchrome(D3Tree(policy, state)) .", 
            "title": "Visualization"
        }, 
        {
            "location": "/#incorporating-additional-prior-knowledge", 
            "text": "An example of incorporating additional prior domain knowledge (to initialize Q and N) and to get an estimate of the value is  here .", 
            "title": "Incorporating Additional Prior Knowledge"
        }, 
        {
            "location": "/vanilla/", 
            "text": "Vanilla\n\n\nThe \"vanilla\" solver is the most basic version of MCTS. It works well with small discrete state and action spaces.\n\n\nThe solver fields are used to specify solver parameters. All of them can be specified as keyword arguments to the solver constructor.\n\n\n#\n\n\nMCTS.MCTSSolver\n \n \nType\n.\n\n\nMCTS solver type\n\n\nFields:\n\n\nn_iterations::Int64\n    Number of iterations during each action() call.\n    default: 100\n\ndepth::Int64:\n    Maximum rollout horizon and tree depth.\n    default: 10\n\nexploration_constant::Float64:\n    Specifies how much the solver should explore.\n    In the UCB equation, Q + c*sqrt(log(t/N)), c is the exploration constant.\n    default: 1.0\n\nrng::AbstractRNG:\n    Random number generator\n\nestimate_value::Any (rollout policy)\n    Function, object, or number used to estimate the value at the leaf nodes.\n    If this is a function `f`, `f(mdp, s, depth)` will be called to estimate the value.\n    If this is an object `o`, `estimate_value(o, mdp, s, depth)` will be called.\n    If this is a number, the value will be set to that number\n    default: RolloutEstimator(RandomSolver(rng))\n\ninit_Q::Any\n    Function, object, or number used to set the initial Q(s,a) value at a new node.\n    If this is a function `f`, `f(mdp, s, a)` will be called to set the value.\n    If this is an object `o`, `init_Q(o, mdp, s, a)` will be called.\n    If this is a number, Q will be set to that number\n    default: 0.0\n\ninit_N::Any\n    Function, object, or number used to set the initial N(s,a) value at a new node.\n    If this is a function `f`, `f(mdp, s, a)` will be called to set the value.\n    If this is an object `o`, `init_N(o, mdp, s, a)` will be called.\n    If this is a number, N will be set to that number\n    default: 0\n\nenable_tree_vis::Bool:\n    If this is true, extra information needed for tree visualization will\n    be recorded. If it is false, the tree cannot be visualized.\n    default: false\n\n\n\n\nsource", 
            "title": "Vanilla"
        }, 
        {
            "location": "/vanilla/#vanilla", 
            "text": "The \"vanilla\" solver is the most basic version of MCTS. It works well with small discrete state and action spaces.  The solver fields are used to specify solver parameters. All of them can be specified as keyword arguments to the solver constructor.  #  MCTS.MCTSSolver     Type .  MCTS solver type  Fields:  n_iterations::Int64\n    Number of iterations during each action() call.\n    default: 100\n\ndepth::Int64:\n    Maximum rollout horizon and tree depth.\n    default: 10\n\nexploration_constant::Float64:\n    Specifies how much the solver should explore.\n    In the UCB equation, Q + c*sqrt(log(t/N)), c is the exploration constant.\n    default: 1.0\n\nrng::AbstractRNG:\n    Random number generator\n\nestimate_value::Any (rollout policy)\n    Function, object, or number used to estimate the value at the leaf nodes.\n    If this is a function `f`, `f(mdp, s, depth)` will be called to estimate the value.\n    If this is an object `o`, `estimate_value(o, mdp, s, depth)` will be called.\n    If this is a number, the value will be set to that number\n    default: RolloutEstimator(RandomSolver(rng))\n\ninit_Q::Any\n    Function, object, or number used to set the initial Q(s,a) value at a new node.\n    If this is a function `f`, `f(mdp, s, a)` will be called to set the value.\n    If this is an object `o`, `init_Q(o, mdp, s, a)` will be called.\n    If this is a number, Q will be set to that number\n    default: 0.0\n\ninit_N::Any\n    Function, object, or number used to set the initial N(s,a) value at a new node.\n    If this is a function `f`, `f(mdp, s, a)` will be called to set the value.\n    If this is an object `o`, `init_N(o, mdp, s, a)` will be called.\n    If this is a number, N will be set to that number\n    default: 0\n\nenable_tree_vis::Bool:\n    If this is true, extra information needed for tree visualization will\n    be recorded. If it is false, the tree cannot be visualized.\n    default: false  source", 
            "title": "Vanilla"
        }, 
        {
            "location": "/dpw/", 
            "text": "Double Progressive Widening\n\n\nThe double progressive widening DPW solver is useful for problems with large (e.g. continuous) state and action spaces. It gradually expands the tree's branching factor so that the algorithm explores deeply even with large spaces.\n\n\nSee the papers at \nhttps://hal.archives-ouvertes.fr/file/index/docid/542673/filename/c0mcts.pdf\n and \nhttp://arxiv.org/abs/1405.5498\n for a description.\n\n\nThe solver fields are used to specify solver parameters. All of them can be specified as keyword arguments to the solver constructor.\n\n\n#\n\n\nMCTS.DPWSolver\n \n \nType\n.\n\n\nMCTS solver with DPW\n\n\nFields:\n\n\ndepth::Int64:\n    Maximum rollout horizon and tree depth.\n    default: 10\n\nexploration_constant::Float64:\n    Specified how much the solver should explore.\n    In the UCB equation, Q + c*sqrt(log(t/N)), c is the exploration constant.\n    default: 1.0\n\nn_iterations::Int64\n    Number of iterations during each action() call.\n    default: 100\n\nmax_time::Float64\n    Maximum amount of CPU time spent iterating through simulations.\n    default: Inf\n\nk_action::Float64\nalpha_action::Float64\nk_state::Float64\nalpha_state::Float64\n    These constants control the double progressive widening. A new state\n    or action will be added if the number of children is less than or equal to kN^alpha.\n    defaults: k:10, alpha:0.5\n\nkeep_tree::Bool\n    If true, store the tree in the planner for reuse at the next timestep (and every time it is used in the future). There is a computational cost for maintaining the state dictionary necessary for this.\n    default: false\n\nenable_action_pw::Bool\n    If true, enable progressive widening on the action space; if false just use the whole action space.\n    default: true\n\ncheck_repeat_state::Bool\ncheck_repeat_action::Bool\n    When constructing the tree, check whether a state or action has been seen before (there is a computational cost to maintaining the dictionaries necessary for this)\n    default: true\n\nrng::AbstractRNG:\n    Random number generator\n\nestimate_value::Any (rollout policy)\n    Function, object, or number used to estimate the value at the leaf nodes.\n    If this is a function `f`, `f(mdp, s, depth)` will be called to estimate the value.\n    If this is an object `o`, `estimate_value(o, mdp, s, depth)` will be called.\n    If this is a number, the value will be set to that number.\n    default: RolloutEstimator(RandomSolver(rng))\n\ninit_Q::Any\n    Function, object, or number used to set the initial Q(s,a) value at a new node.\n    If this is a function `f`, `f(mdp, s, a)` will be called to set the value.\n    If this is an object `o`, `init_Q(o, mdp, s, a)` will be called.\n    If this is a number, Q will always be set to that number.\n    default: 0.0\n\ninit_N::Any\n    Function, object, or number used to set the initial N(s,a) value at a new node.\n    If this is a function `f`, `f(mdp, s, a)` will be called to set the value.\n    If this is an object `o`, `init_N(o, mdp, s, a)` will be called.\n    If this is a number, N will always be set to that number.\n    default: 0\n\nnext_action::Any\n    Function or object used to choose the next action to be considered for progressive widening.\n    The next action is determined based on the MDP, the state, `s`, and the current `DPWStateNode`, `snode`.\n    If this is a function `f`, `f(mdp, s, snode)` will be called to set the value.\n    If this is an object `o`, `next_action(o, mdp, s, snode)` will be called.\n    default: RandomActionGenerator(rng)\n\n\n\n\nsource", 
            "title": "DPW"
        }, 
        {
            "location": "/dpw/#double-progressive-widening", 
            "text": "The double progressive widening DPW solver is useful for problems with large (e.g. continuous) state and action spaces. It gradually expands the tree's branching factor so that the algorithm explores deeply even with large spaces.  See the papers at  https://hal.archives-ouvertes.fr/file/index/docid/542673/filename/c0mcts.pdf  and  http://arxiv.org/abs/1405.5498  for a description.  The solver fields are used to specify solver parameters. All of them can be specified as keyword arguments to the solver constructor.  #  MCTS.DPWSolver     Type .  MCTS solver with DPW  Fields:  depth::Int64:\n    Maximum rollout horizon and tree depth.\n    default: 10\n\nexploration_constant::Float64:\n    Specified how much the solver should explore.\n    In the UCB equation, Q + c*sqrt(log(t/N)), c is the exploration constant.\n    default: 1.0\n\nn_iterations::Int64\n    Number of iterations during each action() call.\n    default: 100\n\nmax_time::Float64\n    Maximum amount of CPU time spent iterating through simulations.\n    default: Inf\n\nk_action::Float64\nalpha_action::Float64\nk_state::Float64\nalpha_state::Float64\n    These constants control the double progressive widening. A new state\n    or action will be added if the number of children is less than or equal to kN^alpha.\n    defaults: k:10, alpha:0.5\n\nkeep_tree::Bool\n    If true, store the tree in the planner for reuse at the next timestep (and every time it is used in the future). There is a computational cost for maintaining the state dictionary necessary for this.\n    default: false\n\nenable_action_pw::Bool\n    If true, enable progressive widening on the action space; if false just use the whole action space.\n    default: true\n\ncheck_repeat_state::Bool\ncheck_repeat_action::Bool\n    When constructing the tree, check whether a state or action has been seen before (there is a computational cost to maintaining the dictionaries necessary for this)\n    default: true\n\nrng::AbstractRNG:\n    Random number generator\n\nestimate_value::Any (rollout policy)\n    Function, object, or number used to estimate the value at the leaf nodes.\n    If this is a function `f`, `f(mdp, s, depth)` will be called to estimate the value.\n    If this is an object `o`, `estimate_value(o, mdp, s, depth)` will be called.\n    If this is a number, the value will be set to that number.\n    default: RolloutEstimator(RandomSolver(rng))\n\ninit_Q::Any\n    Function, object, or number used to set the initial Q(s,a) value at a new node.\n    If this is a function `f`, `f(mdp, s, a)` will be called to set the value.\n    If this is an object `o`, `init_Q(o, mdp, s, a)` will be called.\n    If this is a number, Q will always be set to that number.\n    default: 0.0\n\ninit_N::Any\n    Function, object, or number used to set the initial N(s,a) value at a new node.\n    If this is a function `f`, `f(mdp, s, a)` will be called to set the value.\n    If this is an object `o`, `init_N(o, mdp, s, a)` will be called.\n    If this is a number, N will always be set to that number.\n    default: 0\n\nnext_action::Any\n    Function or object used to choose the next action to be considered for progressive widening.\n    The next action is determined based on the MDP, the state, `s`, and the current `DPWStateNode`, `snode`.\n    If this is a function `f`, `f(mdp, s, snode)` will be called to set the value.\n    If this is an object `o`, `next_action(o, mdp, s, snode)` will be called.\n    default: RandomActionGenerator(rng)  source", 
            "title": "Double Progressive Widening"
        }
    ]
}